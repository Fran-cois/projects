{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle \n",
    "# Cover Type Prediction of Forests\n",
    "### Author : François Amat\n",
    "### Kaggle ID : AmatFrançois \n",
    "### Kaggle Score : 0.95713\n",
    "### contact : amat.francois@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I import all the libraries I need: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time \n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I read and store to a dataframe the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/train-set.csv\")\n",
    "dftest = pd.read_csv(\"datasets/test-set.csv\")\n",
    "f = open(\"results_accuracy.out\",'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the data into the data I have `df_X` and the data I want to predict `df_y`, I also remove the Id which are not important for the classification.\n",
    "Then, I create a train and test set in order to get measures to get the best classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS = df.Id\n",
    "df_y = df.Cover_Type\n",
    "df_X = df.drop(columns=['Id','Cover_Type'])\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit_transform(df_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a list of classifier I want to test, with adjustable features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth, n_estim = 1000, 1000  # best found during iteration on the kaggle judge.\n",
    "max_depth, n_estim = 5, 5 # In order to quick test.\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estim,n_jobs=15,criterion='entropy')\n",
    "clfBoost = XGBClassifier(nthread=-1,max_depth=max_depth,n_estimators=n_estim)\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 10), random_state=1)\n",
    "classifiers = [\n",
    "    ('classifier', clf),\n",
    "    ('classifierXBGBOOST', clfBoost),\n",
    "    ('classifierMlp',clf_mlp)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a function to evaluate the clf and store the results in the way that the kaggle system can judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(_clf,name=\"out\"):\n",
    "    _clf.fit(df_X, df_y)  # so that parts of the original pipeline are fitted\n",
    "    print(accuracy_score(_clf.predict(X_test),y_test),file=f)\n",
    "    pred = _clf.predict(dftest.drop(columns=['Id']))\n",
    "    print(\"predict done\")\n",
    "    df_to_csv = pd.DataFrame( data = np.array(dftest.Id), columns=['Id'] )\n",
    "    df_to_csv['Cover_type'] = pd.DataFrame(data=pred)\n",
    "    df_to_csv.to_csv(name +'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I fit all classifier, at the end only the xgboost, on all the data. Creating the submit file in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "new clf: classifier\n",
      "predict done\n",
      "Elapsed 8.787 seconds.\n",
      "===========================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================\n",
      "new clf: classifierXBGBOOST\n",
      "predict done\n",
      "Elapsed 74.969 seconds.\n",
      "===========================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================\n",
      "new clf: classifierMlp\n",
      "predict done\n",
      "Elapsed 293.609 seconds.\n",
      "===========================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classfier in classifiers:\n",
    "    start = time.perf_counter()\n",
    "    print(\"===========================================\")\n",
    "    print(\"new clf:\",classfier[0])\n",
    "    clf_ = classfier[1]\n",
    "    evaluate(clf_, name=classfier[0])\n",
    "    print(\"classfier used:\",classfier[0],\"accuracy score:\", accuracy_score(clf_.predict(X_test),y_test), file=f)\n",
    "    elapsed = time.perf_counter() - start \n",
    "    print('Elapsed %.3f seconds.' % elapsed)\n",
    "    print(\"===========================================\")\n",
    "    print(\"====\".replace('=',\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final score: 0.95713\n",
    "I have Changed the max_depth, n_estim , PCA  parameters in order to get the best score. \n",
    "\n",
    "However, I think I can still improve this score with more time and with a grid search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
